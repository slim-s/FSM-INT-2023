{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e545491e-4d74-4a3d-8908-a7e501440ae6",
   "metadata": {},
   "source": [
    "# Predictive maintenance of Lathe machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819db72-d3b2-4eca-953f-6d75dc685401",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing important libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419d5f7a-1cbc-4f98-9e84-f36aae31527b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443be3fd-9b2d-4385-9f64-70a689569155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea6834-0364-4056-ad83-48bdb30bfcbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Importing Vibration Data and converting it to proper Time-series format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3abe66-1a7e-441c-a82d-08c041a3ccb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Experiment details\n",
    "exp = pd.read_excel(\"Data/Experiment Summary.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6196d3b-5b70-4ccf-9c2c-0a31706c5e42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "dataframes = []  # To store the imported data from each file\n",
    "\n",
    "for i in range(1, 61):\n",
    "    file = f\"Data/{i}.xlsx\"\n",
    "    df = pd.read_excel(file)  # Use pd.read_excel() for Excel files\n",
    "    df = df.dropna(axis='columns', how='all')  \n",
    "    df = df.dropna(axis='rows', how='all') \n",
    "    df.columns = ['Time', 'X', 'Y', 'Z']\n",
    "    df = df.iloc[1:]  # Exclude the original header row from the data\n",
    "    df['Time'] = pd.to_datetime(df['Time'], unit='s').dt.time  # Convert 'Time' column to datetime\n",
    "    \n",
    "    # Add experiment details from exp dataframe based on experiment number\n",
    "    experiment_number = i  # Or any other way to determine the experiment number\n",
    "    experiment_row = exp[exp['Experiment'] == experiment_number]\n",
    "    if not experiment_row.empty:\n",
    "        for column in experiment_row.columns[1:]:\n",
    "            df[column] = experiment_row[column].values[0]\n",
    "    \n",
    "    dataframes.append(df)\n",
    "    \n",
    "    print(i)  # To keep an eye on progress\n",
    "\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    dataframes[i]['X'] = pd.to_numeric(dataframes[i]['X'], errors='coerce')\n",
    "    dataframes[i]['Y'] = pd.to_numeric(dataframes[i]['Y'], errors='coerce')\n",
    "    dataframes[i]['Z'] = pd.to_numeric(dataframes[i]['Z'], errors='coerce')\n",
    "    dataframes[i]['Magnitude'] = np.sqrt(dataframes[i]['X']**2 + dataframes[i]['Y']**2 + dataframes[i]['Z']**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f7a137-f093-4cd9-abee-b9aac725c1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "merged_df['Time'] = [t.hour * 3600 + t.minute * 60 + t.second + t.microsecond / 1e6 for t in merged_df['Time']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67520fc-c4c0-4b0e-babb-c54c87fcec1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploratory Data Analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1eec8-1489-4df8-80c2-a8e4cad56517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute the correlation matrix\n",
    "corr=merged_df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(corr, square=True,annot=True,cmap='YlGnBu',linecolor=\"black\")\n",
    "plt.title('Correlation between features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee6801-8fcb-4338-8932-30fe6229f430",
   "metadata": {},
   "source": [
    "#### Following are the observations from correlation heat map:\n",
    "    1) X_acceleration is the most prominent in the magnitude calculated.\n",
    "    2) Surface roughness and feed rate are positively correlated \n",
    "    3) Surface roughness and RPM of spindle are negatively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae8d28-ab16-4fa9-bbe0-ed0f041f6043",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400df76b-b037-4cf3-8f39-9ca3882b3cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculating PSD\n",
    "\n",
    "def calculate_psd(dataframe, fs=1000, w=10):\n",
    "    time = dataframe['Time']\n",
    "    mag = dataframe['Magnitude']\n",
    "    x = dataframe['X']\n",
    "    y = dataframe['Y']\n",
    "    z = dataframe['Z']\n",
    "    \n",
    "    # Convert time values to seconds\n",
    "    time_seconds = [(t.hour * 3600 + t.minute * 60 + t.second + t.microsecond / 1e6) for t in time]\n",
    "\n",
    "    # Apply Hanning window function\n",
    "    window = np.hanning(len(time_seconds))\n",
    "    x_windowed = x * window\n",
    "    y_windowed = y * window\n",
    "    z_windowed = z * window\n",
    "    mag_windowed = mag * window\n",
    "    \n",
    "    # Calculate PSD using periodogram\n",
    "    f, psd_mag = signal.welch(mag_windowed, fs, nperseg=len(time_seconds)/w)\n",
    "    _, psd_x = signal.welch(x_windowed, fs, nperseg=len(time_seconds)/w)\n",
    "    _, psd_y = signal.welch(y_windowed, fs, nperseg=len(time_seconds)/w)\n",
    "    _, psd_z = signal.welch(z_windowed, fs, nperseg=len(time_seconds)/w)\n",
    "\n",
    "    return f, psd_mag, psd_x, psd_y, psd_z\n",
    "\n",
    "\n",
    "# Time_domain plot\n",
    "def time_domain(num):\n",
    "    df = dataframes[num]\n",
    "\n",
    "    fig = px.line(df, x='Time', y='Magnitude', title='Vibration Sensor Data', labels={'Magnitude': 'Acceleration'})\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        paper_bgcolor='darkgrey'\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "\n",
    "#Plotting PSD\n",
    "def freq_domain(frequencies, psd_mag, psd_x, psd_y, psd_z):\n",
    "    # Convert complex PSD values to magnitude\n",
    "    psd_mag_mag = np.abs(psd_mag)\n",
    "    psd_x_mag = np.abs(psd_x)\n",
    "    psd_y_mag = np.abs(psd_y)\n",
    "    psd_z_mag = np.abs(psd_z)\n",
    "    # Create line plots for X, Y, and Z axes\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=frequencies, y=psd_mag_mag, mode='lines', name='Magnitude'))\n",
    "    fig.add_trace(go.Scatter(x=frequencies, y=psd_x_mag, mode='lines', name='X'))\n",
    "    fig.add_trace(go.Scatter(x=frequencies, y=psd_y_mag, mode='lines', name='Y'))\n",
    "    fig.add_trace(go.Scatter(x=frequencies, y=psd_z_mag, mode='lines', name='Z'))\n",
    "    fig.update_layout(\n",
    "        title='Power Spectral Density',\n",
    "        xaxis=dict(title='Frequency'),\n",
    "        yaxis=dict(title='acceleration', type='log'),\n",
    "        showlegend=True,\n",
    "        paper_bgcolor= 'darkgrey',\n",
    "        height=600\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d5de4-3fde-4449-8c58-02131c567548",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calling the function with the DataFrames\n",
    "for j in range(5):\n",
    "    for i in range(j, 60, 20):\n",
    "        print(i)\n",
    "        print(exp.iloc[i])\n",
    "        new = time_domain(i) \n",
    "        experiment, mag, x, y, z = calculate_psd(dataframes[i], fs=1000)\n",
    "        plo = freq_domain(experiment, mag, x, y, z)\n",
    "        \n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b3b62-edd6-4b98-be49-b9f0280a8c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the spectrogram using STFT\n",
    "frequencies, times, spectrogram = signal.spectrogram(merged_df['Magnitude'], fs=1000)\n",
    "\n",
    "# Plot the time-frequency representation\n",
    "plt.pcolormesh(times, frequencies, 10 * np.log10(spectrogram), shading='auto', cmap='inferno')\n",
    "\n",
    "# Configure the plot\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Magnitude Time-Frequency Plot')\n",
    "plt.colorbar(label='Power Spectral Density (dB)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c0017-bacf-4fe5-89cf-4476c134ef4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc8adf-05a6-47ef-98ba-7456664c57da",
   "metadata": {},
   "source": [
    "#### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1153688-983a-400a-9b70-5a56d6f975d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Prepare the Data\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = merged_df.drop('Ra', axis=1)\n",
    "y = merged_df['Ra']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4438d014-6838-432f-90ce-4112fca8ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle the test data sets correspondingly\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998bfe88-c4a9-43ce-b9fe-365ec3effa9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe153c-082c-4114-8bf4-939f984b10ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USING CPU COMPUTATION\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Data Preparation - Assume X and y contain the features and target variable\n",
    "\n",
    "# 2. Import Libraries\n",
    "\n",
    "# 4. Create Random Forest Model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "\n",
    "# 5. Fit the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7. Evaluate the Model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a212b7c-cff2-416d-aa22-553af47ab657",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# USING GPU COMPUTATION\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 3. Create XGBoost Random Forest Model\n",
    "model = XGBRegressor(n_estimators=300, tree_method='gpu_hist')\n",
    "\n",
    "# 4. Fit the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6. Evaluate the Model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Calculate the MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# Print the MAE\n",
    "print('Mean Absolute Error:', mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b5e97-52f7-40bf-9db8-8de95b682e36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d95dfc-0703-4110-b594-fdc65f4c5eb2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with 'y_pred' and 'y_train' columns\n",
    "comparison_df = pd.DataFrame({'y_pred': y_pred, 'y_test': y_test})\n",
    "\n",
    "# Print the DataFrame\n",
    "comparison_df.head(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e1f1e-5cf2-4327-bc2c-5deae716c862",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706c301-34fe-4eaf-adb9-621c4d17a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cuml import SVR\n",
    "\n",
    "# 1. Transfer data to GPU\n",
    "X_train_gpu = cp.asarray(X_train)\n",
    "y_train_gpu = cp.asarray(y_train)\n",
    "X_test_gpu = cp.asarray(X_test)\n",
    "\n",
    "# 2. Create the GPU-based SVM model\n",
    "model_gpu = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# 3. Fit the model\n",
    "model_gpu.fit(X_train_gpu, y_train_gpu)\n",
    "\n",
    "# 4. Make predictions\n",
    "y_pred_gpu = model_gpu.predict(X_test_gpu)\n",
    "\n",
    "# 5. Transfer predictions back to CPU\n",
    "y_pred_cpu = cp.asnumpy(y_pred_gpu)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_cpu)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_cpu)\n",
    "print('Mean Absolute Error:', mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2046eb9-f3bd-4c5d-a788-710c11c8ac44",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19041aa-607f-42aa-8f3c-9ba0b64d1607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 00m 41s]\n",
      "val_loss: 2.300213098526001\n",
      "\n",
      "Best val_loss So Far: 2.097658395767212\n",
      "Total elapsed time: 00h 08m 03s\n",
      "\n",
      "Search: Running Trial #27\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "conv_units        |768               |512               \n",
      "dense_units       |512               |1024              \n",
      "learning_rate     |0.0001            |0.0001            \n",
      "tuner/epochs      |10                |10                \n",
      "tuner/initial_e...|0                 |4                 \n",
      "tuner/bracket     |0                 |2                 \n",
      "tuner/round       |0                 |2                 \n",
      "\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 5s 14ms/step - loss: 7.9534 - mae: 2.2425 - val_loss: 2.0401 - val_mae: 1.1012\n",
      "Epoch 2/10\n",
      "146/272 [===============>..............] - ETA: 1s - loss: 1.6799 - mae: 1.1459"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(build_model, objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuner_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5760\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[0;32m     34\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:176\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py:370\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    369\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28msuper\u001b[39m(Hyperband, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_tuner\\engine\\multi_execution_tuner.py:90\u001b[0m, in \u001b[0;36mMultiExecutionTuner.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m     88\u001b[0m copied_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m---> 90\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopied_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, epoch_values \u001b[38;5;129;01min\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:149\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"For AutoKeras to override.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03mDO NOT REMOVE this function. AutoKeras overrides the function to tune\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    The fit history.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(trial\u001b[38;5;241m.\u001b[39mhyperparameters)\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv1D(hp.Int('conv_units', min_value=64, max_value=2048, step=64),\n",
    "                                  kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(hp.Int('dense_units', min_value=256, max_value=3200, step=128),\n",
    "                                 activation='relu'))\n",
    "    model.add(keras.layers.Dense(960, activation='linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-5, 1e-6, 1e-7]))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Define the tuner\n",
    "tuner = kt.Hyperband(build_model, objective='val_loss', max_epochs=10, factor=3, directory='tuner_results')\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(np.expand_dims(X_train_scaled, axis=-1), y_train, epochs=8, batch_size=5760, validation_data=(np.expand_dims(X_test_scaled, axis=-1), y_test))\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, mae = best_model.evaluate(np.expand_dims(X_test_scaled, axis=-1), y_test)\n",
    "print('Mean Squared Error:', loss)\n",
    "print('Mean Absolute Error:', mae)\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict(np.expand_dims(X_test_scaled, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809e5f0-6479-40e2-a964-4b957e53b2c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "#Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#the CNN Model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(512, kernel_size=4, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00002)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "# Train the CNN Model\n",
    "model.fit(np.expand_dims(X_train_scaled, axis=-1), y_train, epochs=8, batch_size=5760)\n",
    "\n",
    "# Evaluate the CNN Model\n",
    "loss, mae = model.evaluate(np.expand_dims(X_test_scaled, axis=-1), y_test)\n",
    "print('Mean Squared Error:', loss)\n",
    "print('Mean Absolute Error:', mae)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(np.expand_dims(X_test_scaled, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87973e07-2124-4144-bb1c-798b856b1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Save the model\n",
    "model.save('cnn.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84559f-42fe-4195-8820-52c0d56e7fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58127ced-b994-4ec8-9b00-44db5a402232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "# Train the LSTM Model\n",
    "model.fit(np.expand_dims(X_train_scaled, axis=-1), y_train, epochs=10, batch_size=5760)\n",
    "\n",
    "# Evaluate the LSTM Model\n",
    "loss, mae = model.evaluate(np.expand_dims(X_test_scaled, axis=-1), y_test)\n",
    "print('Mean Squared Error:', loss)\n",
    "print('Mean Absolute Error:', mae)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(np.expand_dims(X_test_scaled, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbe5c5-e8c1-4428-9753-c0bafcd3be53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
